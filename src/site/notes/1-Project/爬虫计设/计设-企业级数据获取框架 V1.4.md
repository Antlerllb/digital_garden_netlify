---
{"dg-publish":true,"permalink":"/1-Project/爬虫计设/计设-企业级数据获取框架 V1.4/"}
---

# 1 项目简介
- 开发内容
	- 规范化现有的爬虫框架，并实现监控系统。
- 开发周期
	- 3.10前完成，所以时间紧张。
	- 会有非常明确的分工。
	- 每周7天中，自选6天汇报进度。
- 项目支持
	- 已就业大厂的师兄：指导linux和监控系统部分。（所以只要肯花时间，可以短时间内在最快的路上学习）
	- 我：主要对接Python爬虫的逻辑。
# 2 已有Demo
## 2.1 Crawlab
- 网址：https://crawlab.gdufsdm.cn/
- 账号：admin
- 密码：GDUFSDM_crawlab
- 原Github：https://docs.crawlab.cn/zh/guide/basic-tutorial/
## 2.2 Scrapydweb
- 网址：https://scrapydweb.gdufsdm.cn/
- 账号：admin
- 密码：GDUFSDM_scrapydweb
- 原Github：https://github.com/my8100/scrapydweb?tab=readme-ov-file
## 2.3 Gerapy
- 网址：https://gerapy.gdufsdm.cn
- Django后端：https://gerapy.gdufsdm.cn/admin
- 账号：admin
- 密码：GDUFSDM_gerapy
- 原Github：https://github.com/Gerapy/Gerapy
# 3 目前岗位
## 3.1 岗位A
- 工作
	- Scrapy爬虫框架一半的工作量（Python）
	- 封装容器：将爬虫框架封装进Linux的Docker容器中（Linux+Docker）
	- ScrapydWeb监控系统：将爬虫运行数据部署为网站，并发进企业微信（Python+Linux+Docker）
- 你可以得到
	- 计设第一作者
## 3.2 岗位B
- 工作
	- Scrapy爬虫框架一半的工作量（Python）
	- ETL：控制下游数据库的数据传输（Linux+Mysql）
- 你可以得到
	- 计设第三作者
## 3.3 其他备注
- 分工大体是这样，目前我还在和那个师兄积极沟通，现在先确定人员。
# 4 核心收获：企业级开发经验
- 每年计设都有很多人获奖，但不是所有人都能进大厂。部分同学仓促开发规范性太差，对大厂的需求把握不到位。
- 实验室总有进大厂的师兄师姐，但平时没机会接触到。现在有一个项目，可以接触这个人脉，请教到具体的开发知识。多多沟通，了解到内部消息和内推机会也未可知。
---
{"dg-publish":true,"permalink":"/1-Project/语言习得/2024-03-06_Wed 指令微调和上下文学习实验方案/"}
---

# 1 Baseline
你之前发的知乎文章：[大模型微调案例一：LlaMa-2 + QLoRA - 知乎](https://zhuanlan.zhihu.com/p/673362198)
# 2 对比实验
以下是我看23年In Context Learning论文里出现过的实验（之前没怎么调研指令微调）。有哪些其实是没必要的？有哪些可以试试？还是说做了实验才知道结果？我目前没什么概念。
## 2.1 Shot数量
Zero Shot, 1-Shot, …。
## 2.2 模板的craft程度
打算先定完总体方案，再确定具体的模板文字。
来源：No clues good clues: out of context Lexical Relation Classification
![5-Attachment/Image/In-context learning-20240215.png|400](/img/user/5-Attachment/Image/In-context%20learning-20240215.png)
## 2.3 不同的Example合并方式
来源：FiD-ICL: A Fusion-in-Decoder Approach for Efficient In-Context Learning
![5-Attachment/Image/ICL method-20240213.png|475](/img/user/5-Attachment/Image/ICL%20method-20240213.png)
## 2.4 不同的Label
来源：FiD-ICL: A Fusion-in-Decoder Approach for Efficient In-Context Learning

| 实验设置 | 解释 |
| ---- | ---- |
| No Perturbation |  |
| No Input | remove the inputs but keep the labels |
| Random Label | randomly select one of the valid options as the output |
| Wrong Label | randomly select one of the wrong options |
| No Label | remove the labels but keep the inputs |
# 3 疑问
## 3.1 模型和参数大小的对比？
我们要对比模型和参数大小吗？我看其他论文里有，但我不太确定什么样的机器能跑动什么样的模型。
其他论文的实验（FiD-ICL: A Fusion-in-Decoder Approach for Efficient In-Context Learning）：
![5-Attachment/Image/ICL Perturbation-20240214.png|400](/img/user/5-Attachment/Image/ICL%20Perturbation-20240214.png)
## 3.2 微调参数
微调中有很多参数，我目前只了解一些通用（learning_rate、batch_size等），其他的参数需要仔细看吗？是不是有些参数是需要微调做实验的？还是我们只修改输入的样本？（例如，下面的PEFT参数）
![5-Attachment/Image/2024-03-06_Wed 指令微调实验-20240306.png|375](/img/user/5-Attachment/Image/2024-03-06_Wed%20%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83%E5%AE%9E%E9%AA%8C-20240306.png)
## 3.3 阅读有关微调的论文？
我对指令微调等等有了概念上的认识，是否有必要花时间看看23年的论文？我之前看的论文都是In Context Learning的。还是说，现在的主要工作是，把实验先跑起来？跑起来再看看其他的。
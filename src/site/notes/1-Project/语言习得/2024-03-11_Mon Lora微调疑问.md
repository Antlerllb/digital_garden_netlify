---
{"dg-publish":true,"permalink":"/1-Project/语言习得/2024-03-11_Mon Lora微调疑问/"}
---

# 1 Lora微调的方式
## 1.1 预训练模型 + 预训练Config
```python
from peft import PeftModel, PeftConfig

config = PeftConfig.from_pretrained("ybelkada/opt-350m-lora")
model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path)
lora_model = PeftModel.from_pretrained(model, "ybelkada/opt-350m-lora")
```
## 1.2 预训练模型+自定义LoraConfig+get_peft_model
```python
from peft import get_peft_model, LoraConfig, TaskType
from transformers import AutoModelForCausalLM

lora_config = LoraConfig(
    r=16,
    target_modules=["q_proj", "v_proj"],
    task_type=TaskType.CAUSAL_LM,
    lora_alpha=32,
    lora_dropout=0.05
)
model = AutoModelForCausalLM.from_pretrained("facebook/opt-350m")
lora_model = get_peft_model(model, lora_config)
```
## 1.3 预训练模型+自定义LoraConfig+add_adapter
```python
from transformers import AutoModelForCausalLM
from peft import LoraConfig

config = LoraConfig(
    lora_alpha=16,
    lora_dropout=0.1,
    r=64,
    bias="none",
    task_type="CAUSAL_LM"
)
model = AutoModelForCausalLM.from_pretrained("facebook/opt-350m")
model.add_adapter(peft_config)
```

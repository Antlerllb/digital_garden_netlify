---
{"dg-publish":true,"permalink":"/1-Project/语言习得/实验结果与摘要模型/"}
---

# 1 实验结果（bawe数据集）
修改模板后，人工查看输出情况。30个样本中，能预测的概率为83%。
## 1.1 能预测的样本中（25个）
- 正确率
	- 40%
- 输出类型
	- 88%：直接输出first和second。
	- 12%：用罕见单词指代某篇文章（样本27：essay2提到了Tom，模型预测：... is the one written by Mancur Olson ）。
## 1.2 无法预测的样本中（5个）
- 40%没回答：重复输出“the one”，而没说清楚是“the first one”还是“the second one”。
- 60%没输出：模型直接在prompt后面加句号。
- 备注：这个比例不一定准，因为目前无法预测的样本就5个。
# 2 ACL和EMNLP的摘要模型
## 2.1 摘要
| 论文                                                                                                                            | 备注                                            |
|-------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------|
| Generating EDU Extracts for Plan-Guided Summary Re-Ranking                                                                    | 摘要候选对象的排序                                     |
| From Key Points to Key Point Hierarchy: Structured and Expressive Opinion Summarization - ACL Anthology                       | 分析文本关键点再摘要                                    |
| Z-Code++: A Pre-trained Language Model Optimized for Abstractive Summarization - ACL Anthology                                | 预训练模型                                         |
| Incorporating Distributions of Discourse Structure for Long Document Abstractive Summarization - ACL Anthology                | 考虑语篇结构再摘要                                     |
| Improving the Robustness of Summarization Systems with Dual Augmentation - ACL Anthology                                      | 复杂                                            |
| Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method - ACL Anthology | 大模型                                           |
| SIMSUM: Document-level Text Simplification via Simultaneous Summarization - ACL Anthology                                     | 文档级文本简化                                       |
| Socratic Pretraining: Question-Driven Pretraining for Controllable Summarization - ACL Anthology                              | 大模型                                           |
| From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting - ACL Anthology                                     | 大模型                                           |
| UniSumm and SummZoo: Unified Model and Diverse Benchmark for Few-Shot Summarization - ACL Anthology                           | 预训练模型                                         |
| Boosting Summarization with Normalizing Flows and Aggressive Training - ACL Anthology                                         | transformer                                   |
| Investigating Efficiently Extending Transformers for Long Input Summarization - ACL Anthology                                 | 针对长序列，和我们的需求很像。使用了google的pegasus。TF框架，需要新建环境。 |
## 2.2 其他
| 论文                                                                                                            | 备注                    |
|---------------------------------------------------------------------------------------------------------------|-----------------------|
| Extractive is not Faithful: An Investigation of Broad Unfaithfulness Problems in Extractive Summarization     | 摘要审核                  |
| Zero-shot Faithfulness Evaluation for Text Summarization with Foundation Language Model - ACL Anthology       | 摘要审核                  |
| When Do Pre-Training Biases Propagate to Downstream Tasks? A Case Study in Text Summarization - ACL Anthology | Case Study：摘要对下游任务的影响 |
# 3 正在进行的工作
- 转换：推断文本->bool
	- 目前的标签是人工来判断的，没办法批量运行。
- 另一个英语数据集（pelic）的推断
	- 这个数据集比较大，明早（3.17）可以出结果。
# 4 打算进行的工作
- 实现文本摘要模块。
- 筛选文章对：如果2篇文章的撰写时间比较近，就去除这些样本。
# 5 疑问
- 目前的正确率和随机预测没什么区别，但是又想不出来原因，所以直接炼丹？
- 我没太懂user modeling，它的输入和输出是什么？一般大家是怎么实现的？
- 之前论文的数据集是葡萄牙语和西班牙语的。对于这2个语言，一般大家用什么大模型？

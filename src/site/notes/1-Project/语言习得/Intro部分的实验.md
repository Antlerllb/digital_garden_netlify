---
{"dg-publish":true,"permalink":"/1-Project/语言习得/Intro部分的实验/"}
---

# 1 实验+结论（Introduction）
[[5-Attachment/ZoteroNote/@BLiMPBenchmark_2020_Warstadt\|@BLiMPBenchmark_2020_Warstadt]]
**We evaluate whether** the LM assigns a higher probability to the acceptable sentence in each minimal pair **to determine which** grammatical distinctions LMs are sensitive to.
**This gives us indirect evidence about** each model’s linguistic knowledge and allows us to compare models in a fine-grained way.
# 2 效果好
[[5-Attachment/ZoteroNote/@BLiMPBenchmark_2020_Warstadt\|@BLiMPBenchmark_2020_Warstadt]]
**We conclude that** current neural LMs **appear to acquire robust knowledge** of morphological agreement and some syntactic phenomena such as ellipsis and control/ raising.

[[5-Attachment/ZoteroNote/@BLiMPBenchmark_2020_Warstadt\|@BLiMPBenchmark_2020_Warstadt]]
Although we see **steady improvements in overall performance**, we find that LMs learn phenomenon-specific distinctions at different rates.
# 3 效果差
[[5-Attachment/ZoteroNote/@BLiMPBenchmark_2020_Warstadt\|@BLiMPBenchmark_2020_Warstadt]]
**They show weaker evidence of** knowledge about argument structure, negative polarity item licensing, and the semantic properties of quantifiers.

[[5-Attachment/ZoteroNote/@BLiMPBenchmark_2020_Warstadt\|@BLiMPBenchmark_2020_Warstadt]] #human-performance
Overall, every model we evaluate **falls short of human performance by a wide margin**.
GPT-2, which **performs the best**, performs 8 points **below humans overall**, though it does match or exceed human performance on specific phenomena.

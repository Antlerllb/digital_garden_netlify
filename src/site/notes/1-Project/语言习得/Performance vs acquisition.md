---
{"dg-publish":true,"permalink":"/1-Project/语言习得/Performance vs acquisition/"}
---

# 1 Human-like ways
[[5-Attachment/ZoteroNote/@EvaluatingNeural_2023_VazquezMartinez\|@EvaluatingNeural_2023_VazquezMartinez]]
#gap 
- If there are any potentially **unrecognized non-human-like ways** to succeed at the task. (if an evaluation can be solved in unintended ways)
- or if the task does not **truly reflect acquisition**
- or the task does not actually test a relevant **structural property of language**
-> **then a positive result becomes inconclusive at best.** (underlying assumption?: Positive results on such benchmarks are a demonstration of human-like representations or human-like language acquisition)

- may be fraught
	- “if a (neural) model X behaves like cognitive system Y, then it is equivalent to Y” (Guest and Martin, 2023)

Good, even human-like, performance on NLP tasks does not necessarily imply that LMs solve these in humanlike ways.
# 2 Perturbation
[[1-Project/语言习得/ICL Perturbation\|ICL Perturbation]]
# 3 Distribution of inputs and labels
[[1-Project/语言习得/Zero-shot Pseudo-Demonstrations\|Zero-shot Pseudo-Demonstrations]]

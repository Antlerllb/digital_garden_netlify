---
{"dg-publish":true,"permalink":"/5-Attachment/ZoteroNote/@TrackingChild_2021_Sagae/","title":"Tracking Child Language Development With Neural Network Language Models"}
---

# Tracking Child Language Development With Neural Network Language Models
## Link
- File: [Available Version (via Google Scholar)](zotero://open-pdf/library/items/E7U6F4F3); [TrackingChild_2021_Sagae.pdf](zotero://open-pdf/library/items/XMJE775G)
- Url: https://www.frontiersin.org/articles/10.3389/fpsyg.2021.674402/full
- Item: [item](zotero://select/library/items/YZ6LK9PR)
## Abstract
Recent work on the application of neural networks to language modeling has shown that models based on certain neural architectures can capture syntactic information from utterances and sentences even when not given an explicitly syntactic objective. We examine whether a fully data-driven model of language development that uses a recurrent neural network encoder for utterances can track how child language utterances change over the course of language development in a way that is comparable to what is achieved using established language assessment metrics that use language-specific information carefully designed by experts. Given only transcripts of child language utterances from the CHILDES Database and no pre-specified information about language, our model captures not just the structural characteristics of child language utterances, but how these structures reflect language development over time. We establish an evaluation methodology with which we can examine how well our model tracks language development compared to three known approaches: Mean Length of Utterance, the Developmental Sentence Score, and the Index of Productive Syntax. We discuss the applicability of our model to data-driven assessment of child language development, including how a fully data-driven approach supports the possibility of increased research in multilingual and cross-lingual issues.
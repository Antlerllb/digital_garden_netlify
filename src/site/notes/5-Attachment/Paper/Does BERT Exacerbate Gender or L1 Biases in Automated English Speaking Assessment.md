---
{"dg-publish":true,"permalink":"/5-Attachment/Paper/Does BERT Exacerbate Gender or L1 Biases in Automated English Speaking Assessment/"}
---

# 1 Does BERT Exacerbate Gender or L1 Biases in Automated English Speaking Assessment?
## 1.1 Link
pdf: "[zotero.pdf](zotero://open-pdf/library/items/AFZAI7KT)"
url: "[https://aclanthology.org/2023.bea-1.54](https://aclanthology.org/2023.bea-1.54)"
doi: "[10.18653/v1/2023.bea-1.54](https://doi.org/10.18653/v1/2023.bea-1.54)"
## 1.2 Abstract
In English speaking assessment, pretrained large language models (LLMs) such as BERT can score constructed response items as accurately as human raters. Less research has investigated whether LLMs perpetuate or exacerbate biases, which would pose problems for the fairness and validity of the test. This study examines gender and native language (L1) biases in human and automated scores, using an off-the-shelf (OOS) BERT model. Analyses focus on a specific type of bias known as differential item functioning (DIF), which compares examinees of similar English language proficiency. Results show that there is a moderate amount of DIF, based on examinees' L1 background in grade band 912. DIF is higher when scored by an OOS BERT model, indicating that BERT may exacerbate this bias; however, in practical terms, the degree to which BERT exacerbates DIF is very small. Additionally, there is more DIF for longer speaking items and for older examinees, but BERT does not exacerbate these patterns of DIF.